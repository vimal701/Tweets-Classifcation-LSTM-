{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= pd.read_csv(r'C:\\Users\\vikil\\Desktop\\ML\\data_Sets\\twitter\\train.csv')\n",
    "test=pd.read_csv(r'C:\\Users\\vikil\\Desktop\\ML\\data_Sets\\twitter\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop(['keyword','location'],axis=1)\n",
    "test=test.drop(['keyword','location'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for i in range(0,len(train)):\n",
    "    review=re.sub('[^a-z]',' ',train['text'][i])\n",
    "    review=review.lower()\n",
    "    review=review.split()\n",
    "    \n",
    "    review= [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review=' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_repr=[one_hot(words, voc_size) for words in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_length=20\n",
    "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 20, 40)            200000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 200)               112800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 313,001\n",
      "Trainable params: 313,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_features=40\n",
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
    "model.add(Bidirectional(LSTM(100)))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_final=np.array(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final=np.array(train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7613/7613 [==============================] - 26s 3ms/sample - loss: 0.5798 - acc: 0.6903\n",
      "Epoch 2/10\n",
      "7613/7613 [==============================] - 21s 3ms/sample - loss: 0.3900 - acc: 0.8316\n",
      "Epoch 3/10\n",
      "7613/7613 [==============================] - 22s 3ms/sample - loss: 0.3153 - acc: 0.8736\n",
      "Epoch 4/10\n",
      "7613/7613 [==============================] - 21s 3ms/sample - loss: 0.2594 - acc: 0.9027\n",
      "Epoch 5/10\n",
      "7613/7613 [==============================] - 21s 3ms/sample - loss: 0.2068 - acc: 0.9257\n",
      "Epoch 6/10\n",
      "7613/7613 [==============================] - 21s 3ms/sample - loss: 0.1617 - acc: 0.9480\n",
      "Epoch 7/10\n",
      "7613/7613 [==============================] - 22s 3ms/sample - loss: 0.1350 - acc: 0.9573\n",
      "Epoch 8/10\n",
      "7613/7613 [==============================] - 24s 3ms/sample - loss: 0.1173 - acc: 0.9628\n",
      "Epoch 9/10\n",
      "7613/7613 [==============================] - 24s 3ms/sample - loss: 0.1009 - acc: 0.9695\n",
      "Epoch 10/10\n",
      "7613/7613 [==============================] - 24s 3ms/sample - loss: 0.0834 - acc: 0.97460s - loss: 0.0840 - acc: 0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e6467f5648>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_final,y_final,epochs=10,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text\n",
       "0         0                 Just happened a terrible car crash\n",
       "1         2  Heard about #earthquake is different cities, s...\n",
       "2         3  there is a forest fire at spot pond, geese are...\n",
       "3         9           Apocalypse lighting. #Spokane #wildfires\n",
       "4        11      Typhoon Soudelor kills 28 in China and Taiwan\n",
       "...     ...                                                ...\n",
       "3258  10861  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...\n",
       "3259  10865  Storm in RI worse than last hurricane. My city...\n",
       "3260  10868  Green Line derailment in Chicago http://t.co/U...\n",
       "3261  10874  MEG issues Hazardous Weather Outlook (HWO) htt...\n",
       "3262  10875  #CityofCalgary has activated its Municipal Eme...\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_test=[]\n",
    "for i in range(0,len(test)):\n",
    "    review=re.sub('[^a-z]',' ',test['text'][i])\n",
    "    review=review.lower()\n",
    "    review=review.split()\n",
    "    \n",
    "    review= [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review=' '.join(review)\n",
    "    corpus_test.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_repr_test=[one_hot(words, voc_size) for words in corpus_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_docs_test=pad_sequences(onehot_repr_test,padding='pre',maxlen=sent_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=np.array(embedded_docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred=model.predict_classes(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['Id'] = test_id\n",
    "sub['target'] = final_pred\n",
    "sub.to_csv(r'C:\\Users\\vikil\\Desktop\\ML\\data_Sets\\twitter\\submission_new_seq.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
